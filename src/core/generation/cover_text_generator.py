"""
AIå°é¢æ–‡å­—ç”Ÿæˆå™¨
æ ¹æ®å†…å®¹è‡ªåŠ¨ç”Ÿæˆé€‚åˆçš„å°é¢æ ‡é¢˜å’Œæ–‡æ¡ˆ
"""

import json
import re
from typing import Dict, List, Optional, Tuple
from ..ai_integration.ai_provider_factory import AIProviderFactory


class CoverTextGenerator:
    """AIå°é¢æ–‡å­—ç”Ÿæˆå™¨"""
    
    def __init__(self):
        # æš‚æ—¶ä½¿ç”¨æ¨¡æ‹ŸAIæœåŠ¡ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦é…ç½®APIå¯†é’¥
        self.ai_provider = None
    
    def generate_cover_text(self, content: str, platform: str = "xiaohongshu", 
                          style: str = "attractive", target_audience: str = "å¹´è½»å¥³æ€§") -> Dict[str, str]:
        """
        ç”Ÿæˆå°é¢æ–‡å­—
        
        Args:
            content: åŸå§‹å†…å®¹æ–‡æœ¬
            platform: å¹³å°ç±»å‹ (xiaohongshu, douyin, weiboç­‰)
            style: æ–‡æ¡ˆé£æ ¼ (attractive, professional, cute, luxuryç­‰)
            target_audience: ç›®æ ‡å—ä¼—
            
        Returns:
            åŒ…å«å°é¢æ–‡å­—çš„dict: {
                'main_title': ä¸»æ ‡é¢˜,
                'subtitle': å‰¯æ ‡é¢˜,
                'tags': æ ‡ç­¾åˆ—è¡¨,
                'emojis': æ¨èemoji
            }
        """
        
        # æš‚æ—¶ä½¿ç”¨å›é€€ç”Ÿæˆç­–ç•¥ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦é…ç½®AIæœåŠ¡
        return self._fallback_generation(content, style)
    
    def _build_prompt(self, content: str, platform: str, style: str, target_audience: str) -> str:
        """æ„å»ºAIæç¤ºè¯"""
        
        platform_guides = {
            "xiaohongshu": "å°çº¢ä¹¦ç”¨æˆ·å–œæ¬¢çœŸå®åˆ†äº«ã€ç”Ÿæ´»åŒ–è¡¨è¾¾ï¼Œæ ‡é¢˜è¦æœ‰ä»£å…¥æ„Ÿå’Œå®ç”¨æ€§",
            "douyin": "æŠ–éŸ³ç”¨æˆ·å–œæ¬¢ç®€æ´æœ‰åŠ›ã€æœ‰å†²å‡»åŠ›çš„æ ‡é¢˜ï¼Œé€‚åˆçŸ­è§†é¢‘èŠ‚å¥",
            "weibo": "å¾®åšç”¨æˆ·å–œæ¬¢è¯é¢˜æ€§å¼ºã€æœ‰äº‰è®®æ€§çš„æ ‡é¢˜"
        }
        
        style_guides = {
            "attractive": "å¸å¼•äººã€æœ‰å†²å‡»åŠ›ï¼Œä½¿ç”¨emojiå’Œçƒ­é—¨è¯æ±‡",
            "professional": "ä¸“ä¸šæƒå¨ï¼Œä½¿ç”¨è¡Œä¸šæœ¯è¯­å’Œæ•°æ®æ”¯æ’‘",
            "cute": "å¯çˆ±ä¿çš®ï¼Œä½¿ç”¨ç½‘ç»œæµè¡Œè¯­å’Œè¡¨æƒ…",
            "luxury": "é«˜ç«¯å¥¢åï¼Œçªå‡ºå“è´¨å’Œç‹¬ç‰¹æ€§"
        }
        
        prompt = f"""
        è¯·ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆé€‚åˆ{platform}å¹³å°çš„å°é¢æ–‡å­—ï¼š
        
        å†…å®¹ï¼š{content[:500]}...
        
        è¦æ±‚ï¼š
        1. ä¸»æ ‡é¢˜ï¼š{style_guides.get(style, 'å¸å¼•äºº')}ï¼Œ15å­—ä»¥å†…
        2. å‰¯æ ‡é¢˜ï¼šè¡¥å……è¯´æ˜ï¼Œ20å­—ä»¥å†…
        3. æ ‡ç­¾ï¼š3-5ä¸ªç›¸å…³æ ‡ç­¾ï¼Œå¸¦#
        4. emojiï¼š2-4ä¸ªåˆé€‚çš„emoji
        
        å¹³å°ç‰¹ç‚¹ï¼š{platform_guides.get(platform, 'é€šç”¨')}
        ç›®æ ‡å—ä¼—ï¼š{target_audience}
        
        è¯·è¿”å›JSONæ ¼å¼ï¼š
        {{
            "main_title": "ä¸»æ ‡é¢˜",
            "subtitle": "å‰¯æ ‡é¢˜",
            "tags": ["#æ ‡ç­¾1", "#æ ‡ç­¾2", "#æ ‡ç­¾3"],
            "emojis": ["emoji1", "emoji2"]
        }}
        """
        
        return prompt
    
    def _parse_response(self, response: str) -> Dict[str, str]:
        """è§£æAIå“åº”"""
        
        try:
            # å°è¯•è§£æJSON
            data = json.loads(response.strip())
            return {
                'main_title': data.get('main_title', ''),
                'subtitle': data.get('subtitle', ''),
                'tags': data.get('tags', []),
                'emojis': data.get('emojis', [])
            }
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–
            return self._extract_from_text(response)
    
    def _extract_from_text(self, text: str) -> Dict[str, str]:
        """ä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯"""
        lines = text.strip().split('\n')
        
        # æå–æ ‡é¢˜ï¼ˆé€šå¸¸åœ¨ç¬¬ä¸€è¡Œï¼‰
        main_title = lines[0].strip() if lines else "ç²¾å½©å†…å®¹"
        if len(main_title) > 15:
            main_title = main_title[:15]
        
        # æå–å‰¯æ ‡é¢˜ï¼ˆç¬¬äºŒè¡Œæˆ–å‰©ä½™å†…å®¹ï¼‰
        subtitle = ""
        if len(lines) > 1:
            subtitle = lines[1].strip()
            if len(subtitle) > 20:
                subtitle = subtitle[:20]
        
        # æå–æ ‡ç­¾
        tags = re.findall(r'#[\u4e00-\u9fa5\w]+', text)
        if not tags:
            tags = ["#åˆ†äº«", "#ç”Ÿæ´»"]
        
        # æå–emoji
        emojis = re.findall(r'[ğŸ˜€-ğŸ™ğŸŒ€-ğŸ—¿ğŸš€-ğŸ›¿]', text)
        if not emojis:
            emojis = ["âœ¨", "ğŸ”¥"]
        
        return {
            'main_title': main_title,
            'subtitle': subtitle,
            'tags': tags[:5],
            'emojis': emojis[:4]
        }
    
    def _fallback_generation(self, content: str, style: str) -> Dict[str, str]:
        """å›é€€ç”Ÿæˆç­–ç•¥"""
        
        # ä»å†…å®¹ä¸­æå–å…³é”®è¯
        keywords = self._extract_keywords(content)
        
        templates = {
            "attractive": {
                "main_title": f"{keywords[0] if keywords else 'è¶…å®ç”¨'}åˆ†äº«ï¼",
                "subtitle": f"{keywords[1] if len(keywords) > 1 else 'ä¸çœ‹åæ‚”'}",
                "tags": ["#å¹²è´§", "#åˆ†äº«", f"#{keywords[0] if keywords else 'ç”Ÿæ´»'}"],
                "emojis": ["âœ¨", "ğŸ”¥"]
            },
            "professional": {
                "main_title": f"{keywords[0] if keywords else 'ä¸“ä¸š'}æŒ‡å—",
                "subtitle": f"{keywords[1] if len(keywords) > 1 else 'æ·±åº¦è§£æ'}",
                "tags": ["#çŸ¥è¯†", "#å¹²è´§", f"#{keywords[0] if keywords else 'ä¸“ä¸š'}"],
                "emojis": ["ğŸ“š", "ğŸ’¡"]
            },
            "cute": {
                "main_title": f"{keywords[0] if keywords else 'å¯çˆ±'}åˆ°çˆ†ï¼",
                "subtitle": f"{keywords[1] if len(keywords) > 1 else 'å°‘å¥³å¿ƒçˆ†æ£š'}",
                "tags": ["#å¯çˆ±", "#æ—¥å¸¸", f"#{keywords[0] if keywords else 'åˆ†äº«'}"],
                "emojis": ["ğŸ’–", "ğŸ€"]
            },
            "luxury": {
                "main_title": f"{keywords[0] if keywords else 'é«˜ç«¯'}ç”Ÿæ´»",
                "subtitle": f"{keywords[1] if len(keywords) > 1 else 'å“è´¨ä¹‹é€‰'}",
                "tags": ["#å“è´¨", "#ç”Ÿæ´»", f"#{keywords[0] if keywords else 'ç²¾è‡´'}"],
                "emojis": ["ğŸ’", "âœ¨"]
            }
        }
        
        return templates.get(style, templates["attractive"])
    
    def _extract_keywords(self, content: str) -> List[str]:
        """ä»å†…å®¹ä¸­æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–é€»è¾‘
        # å®é™…é¡¹ç›®ä¸­å¯ä»¥ä½¿ç”¨jiebaåˆ†è¯æˆ–æ›´å¤æ‚çš„NLPæŠ€æœ¯
        
        content = content[:200]  # é™åˆ¶é•¿åº¦
        
        # å¸¸è§å…³é”®è¯è¯å…¸
        keywords_dict = {
            "æŠ¤è‚¤": ["æŠ¤è‚¤", "ä¿å…»", "çš®è‚¤", "é¢è†œ", "ç²¾å"],
            "ç¾å¦†": ["åŒ–å¦†", "å£çº¢", "çœ¼å½±", "ç²‰åº•", "ç¾å¦†"],
            "ç©¿æ­": ["ç©¿æ­", "è¡£æœ", "æ—¶å°š", "æ­é…", "OOTD"],
            "ç¾é£Ÿ": ["ç¾é£Ÿ", "æ–™ç†", "é¤å…", "é£Ÿè°±", "åƒè´§"],
            "æ—…è¡Œ": ["æ—…è¡Œ", "æ—…æ¸¸", "æ”»ç•¥", "æ™¯ç‚¹", "é…’åº—"],
            "å¥èº«": ["å¥èº«", "å‡è‚¥", "è¿åŠ¨", "ç‘œä¼½", "å¡‘å½¢"],
            "å­¦ä¹ ": ["å­¦ä¹ ", "è€ƒè¯•", "å¤ä¹ ", "ç¬”è®°", "å¹²è´§"],
            "èŒåœº": ["èŒåœº", "å·¥ä½œ", "ç®€å†", "é¢è¯•", "å‡èŒ"]
        }
        
        matched_keywords = []
        for category, words in keywords_dict.items():
            for word in words:
                if word in content:
                    matched_keywords.append(category)
                    break
        
        return matched_keywords[:3] if matched_keywords else ["ç”Ÿæ´»", "åˆ†äº«"]
    
    def optimize_for_platform(self, text: str, platform: str) -> str:
        """é’ˆå¯¹å¹³å°ä¼˜åŒ–æ–‡å­—"""
        
        platform_limits = {
            "xiaohongshu": {"title": 20, "subtitle": 30},
            "douyin": {"title": 15, "subtitle": 20},
            "weibo": {"title": 30, "subtitle": 50}
        }
        
        limits = platform_limits.get(platform, {"title": 20, "subtitle": 30})
        
        # æ ¹æ®å¹³å°é™åˆ¶æˆªæ–­æ–‡å­—
        if len(text) > limits["title"]:
            text = text[:limits["title"]-1] + "â€¦"
        
        return text
    
    def generate_batch_texts(self, content: str, count: int = 5) -> List[Dict[str, str]]:
        """æ‰¹é‡ç”Ÿæˆå¤šä¸ªå°é¢æ–‡å­—æ–¹æ¡ˆ"""
        
        results = []
        styles = ["attractive", "professional", "cute", "luxury"]
        
        for i in range(count):
            style = styles[i % len(styles)]
            text = self.generate_cover_text(content, style=style)
            text["style"] = style
            results.append(text)
        
        return results